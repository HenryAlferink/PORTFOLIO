{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinkedIn Learning Course:\n",
    "# Python: Working with Predictive Analytics\n",
    "https://www.linkedin.com/learning/python-working-with-predictive-analytics/predict-data-in-python\n",
    "\n",
    "**Course Author:** Isil Berkun\n",
    "\n",
    "This notebook is the course content put into my own words/code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler, \n",
    "    StandardScaler, \n",
    "    OneHotEncoder, \n",
    "    LabelEncoder, \n",
    "    PolynomialFeatures\n",
    ")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def eg(obj, msg=None):\n",
    "    \"\"\"Convenience function for displaying output.\"\"\"\n",
    "    print()\n",
    "    if msg:\n",
    "        print(msg)\n",
    "    else:\n",
    "        print(\"E.g.\")\n",
    "    display(obj)\n",
    "\n",
    "def split_and_scale(X, y, random_state=None):\n",
    "    \"\"\"Convenience function used to split the data into test and train sets, and to scale the independent variables.\"\"\"\n",
    "    if random_state:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=random_state)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    \n",
    "    # standardize features: take away the mean, and scale to unit variance\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train.astype(np.float))\n",
    "    X_test= sc.transform(X_test.astype(np.float))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv(\"Exercise Files/Datasets/insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         5\n",
       "children    0\n",
       "smoker      0\n",
       "region      0\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a Series object that shows how many null values (e.g. NaN's) each column has. \n",
    "count_nan = data.isnull().sum()\n",
    "count_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bmi    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_nan[count_nan > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPUTATION:\n",
    "Here we fill the NaN values with the column mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now there are no NaN values remaining:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill the nan values with the column mean\n",
    "data['bmi'].fillna(data['bmi'].mean(), inplace=True)\n",
    "count_nan = data.isnull().sum()\n",
    "\n",
    "print(\"Now there are no NaN values remaining:\")\n",
    "count_nan[count_nan > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An example of categorical variables:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>female</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sex smoker\n",
       "0     female    yes\n",
       "1       male     no\n",
       "2       male     no\n",
       "3       male     no\n",
       "4       male     no\n",
       "...      ...    ...\n",
       "1333    male     no\n",
       "1334  female     no\n",
       "1335  female     no\n",
       "1336  female     no\n",
       "1337  female    yes\n",
       "\n",
       "[1338 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eg(\n",
    "    data.iloc[:, [1,4]], \n",
    "    \"An example of categorical variables:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['female']\n",
      " ['male']\n",
      " ['male']\n",
      " ...\n",
      " ['female']\n",
      " ['female']\n",
      " ['female']]\n"
     ]
    }
   ],
   "source": [
    "# turn the above two columns into ndarrays so that we can pass them to sklearn for label encoding.\n",
    "sex = data.iloc[:, 1:2].values\n",
    "smoker = data.iloc[:, 4:5].values\n",
    "print(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female' 'male' 'male' ... 'female' 'female' 'female']\n"
     ]
    }
   ],
   "source": [
    "print(sex[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the categorical data into numerical\n",
    "This is necessary, as the computer can only work with numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An example of how the categorical variable has been turned into a numerical one:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sex = data.iloc[:, 1:2].values\n",
    "\n",
    "# class used to encode categorical features into numerical\n",
    "le = LabelEncoder()\n",
    "\n",
    "eg(\n",
    "    le.fit_transform(sex[:,0]),\n",
    "    \"An example of how the categorical variable has been \"\n",
    "    \"turned into a numerical one:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the reason for the funny indexing is that it turns the array into\n",
    "# a 1D array, and then assigns it to an object of the same shape\n",
    "sex[:,0] = le.fit_transform(sex[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 1D array:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original array:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eg(\n",
    "    sex[:,0],\n",
    "    \"The 1D array:\"\n",
    ")\n",
    "eg(\n",
    "    sex,\n",
    "    \"Original array:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex\n",
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "...   ..\n",
       "1333   1\n",
       "1334   0\n",
       "1335   0\n",
       "1336   0\n",
       "1337   0\n",
       "\n",
       "[1338 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex = pd.DataFrame(sex)\n",
    "sex.columns = ['sex']\n",
    "sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sex mapping:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'female': 0, 'male': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# related to the above...\n",
    "le_sex_mapping = dict(list(zip(le.classes_, le.transform(le.classes_))))\n",
    "eg(le_sex_mapping, \"sex mapping:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "smoker column turned into binary variable:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smoker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     smoker\n",
       "0         1\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "...     ...\n",
       "1333      0\n",
       "1334      0\n",
       "1335      0\n",
       "1336      0\n",
       "1337      1\n",
       "\n",
       "[1338 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "smoker mapping:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'no': 0, 'yes': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's do the same as what we did for the sex column but now for the 'smoker' column\n",
    "\n",
    "smoker = data.iloc[:, 4:5].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "smoker[:,0] = le.fit_transform(smoker[:,0])\n",
    "smoker = pd.DataFrame(smoker, columns=['smoker'])\n",
    "le_smoker_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "eg(smoker, \"smoker column turned into binary variable:\")\n",
    "eg(le_smoker_mapping, \"smoker mapping:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "The 'region' column of the dataset has more than two categories. Therefore we cannot simply use a binary variable. We will need to use one-hot encoding. This is where we output multiple binary columns, one for each category. E.g. a 1 in the \"southeast\" column and a 0 in the other three will then mean that \"southeast\" is the selected category for the observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['southwest' 'southeast' 'northwest' 'northeast']\n"
     ]
    }
   ],
   "source": [
    "print(data['region'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['southwest'],\n",
       "       ['southeast'],\n",
       "       ['southeast'],\n",
       "       ...,\n",
       "       ['southeast'],\n",
       "       ['southwest'],\n",
       "       ['northwest']], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that \"[:, np.newaxis]\" applied on the numpy array turns the \n",
    "# 1D array into a 2D array, which is required for the OneHotEncoder class.\n",
    "\n",
    "region_values = data['region'].values[:, np.newaxis]\n",
    "region_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_values = data.iloc[:,5:6].values\n",
    "\n",
    "# one-hot encoded array. One column for each category. (may need to convert to int. It may be\n",
    "# returning floats because there are NaN values somewhere...)\n",
    "ohe = OneHotEncoder()\n",
    "region_encoded = ohe.fit_transform(region_values).toarray()\n",
    "region_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note that for some reason it comes surrounded by a Python list:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array(['northeast', 'northwest', 'southeast', 'southwest'], dtype=object)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eg(\n",
    "    ohe.categories_,\n",
    "    \"Note that for some reason it comes surrounded by a Python list:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note they're float values. This is probably because there\n",
      "was a NaN value found somewhere (? didn't we get rid of these?).\n",
      "\"The int type can't handle NaN values, so it's converted to float.\n",
      "Look into converting to pd.Int64Dtype().\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>northeast</th>\n",
       "      <th>northwest</th>\n",
       "      <th>southeast</th>\n",
       "      <th>southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      northeast  northwest  southeast  southwest\n",
       "0           0.0        0.0        0.0        1.0\n",
       "1           0.0        0.0        1.0        0.0\n",
       "2           0.0        0.0        1.0        0.0\n",
       "3           0.0        1.0        0.0        0.0\n",
       "4           0.0        1.0        0.0        0.0\n",
       "...         ...        ...        ...        ...\n",
       "1333        0.0        1.0        0.0        0.0\n",
       "1334        1.0        0.0        0.0        0.0\n",
       "1335        0.0        0.0        1.0        0.0\n",
       "1336        0.0        0.0        0.0        1.0\n",
       "1337        0.0        1.0        0.0        0.0\n",
       "\n",
       "[1338 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region = pd.DataFrame(region_encoded, columns=ohe.categories_[0])\n",
    "eg(\n",
    "    region,\n",
    "    \"\"\"Note they're float values. This is probably because there\n",
    "was a NaN value found somewhere (? didn't we get rid of these?).\n",
    "\"The int type can't handle NaN values, so it's converted to float.\n",
    "Look into converting to pd.Int64Dtype().\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PUTTING THINGS TOGETHER\n",
    "Put all cleaned features back into one dataframe. Here we also split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>northeast</th>\n",
       "      <th>northwest</th>\n",
       "      <th>southeast</th>\n",
       "      <th>southwest</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>25</td>\n",
       "      <td>34.485</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>19</td>\n",
       "      <td>34.700</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>52</td>\n",
       "      <td>38.380</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>18</td>\n",
       "      <td>31.350</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>27</td>\n",
       "      <td>26.030</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>42</td>\n",
       "      <td>35.970</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>40</td>\n",
       "      <td>25.080</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>19</td>\n",
       "      <td>35.530</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>33</td>\n",
       "      <td>18.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>896 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  northeast  northwest  southeast  southwest sex  \\\n",
       "1271   25  34.485         0        0.0        1.0        0.0        0.0   0   \n",
       "1313   19  34.700         2        0.0        0.0        0.0        1.0   0   \n",
       "2      28  33.000         3        0.0        0.0        1.0        0.0   1   \n",
       "405    52  38.380         2        1.0        0.0        0.0        0.0   0   \n",
       "482    18  31.350         0        0.0        0.0        1.0        0.0   0   \n",
       "...   ...     ...       ...        ...        ...        ...        ...  ..   \n",
       "763    27  26.030         0        1.0        0.0        0.0        0.0   1   \n",
       "835    42  35.970         2        0.0        0.0        1.0        0.0   1   \n",
       "1216   40  25.080         0        0.0        0.0        1.0        0.0   1   \n",
       "559    19  35.530         0        0.0        1.0        0.0        0.0   1   \n",
       "684    33  18.500         1        0.0        0.0        0.0        1.0   0   \n",
       "\n",
       "     smoker  \n",
       "1271      0  \n",
       "1313      1  \n",
       "2         0  \n",
       "405       0  \n",
       "482       0  \n",
       "...     ...  \n",
       "763       0  \n",
       "835       0  \n",
       "1216      0  \n",
       "559       0  \n",
       "684       0  \n",
       "\n",
       "[896 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numerical = data[['age','bmi','children']].copy()\n",
    "X_final = pd.concat([X_numerical, region, sex, smoker], axis=1)\n",
    "y_final = data[['charges']].copy()\n",
    "\n",
    "# splitting into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.33, random_state = 0)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing features\n",
    "Take away the mean, and scale to unit variance. This is important for some machine learning algorithms to stop variables with larger values taking more precendent in the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "E.g.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.03606235,  0.61468414, -0.91008919, ..., -0.58766091,\n",
       "        -0.98669564, -0.4996512 ],\n",
       "       [-1.46484381,  0.64957783,  0.7540739 , ...,  1.70166159,\n",
       "        -0.98669564,  2.00139616],\n",
       "       [-0.82167162,  0.37367425,  1.58615545, ..., -0.58766091,\n",
       "         1.01348375, -0.4996512 ],\n",
       "       ...,\n",
       "       [ 0.03589131, -0.91171181, -0.91008919, ..., -0.58766091,\n",
       "         1.01348375, -0.4996512 ],\n",
       "       [-1.46484381,  0.78428369, -0.91008919, ..., -0.58766091,\n",
       "         1.01348375, -0.4996512 ],\n",
       "       [-0.46435373, -1.97962095, -0.07800765, ...,  1.70166159,\n",
       "        -0.98669564, -0.4996512 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FEATURE SCALING\n",
    "\n",
    "# normalizing\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(X_train.astype(np.float))\n",
    "# X_test= scaler.transform(X_test.astype(np.float))\n",
    "\n",
    "# standardizing\n",
    "s_scaler = StandardScaler()\n",
    "X_train = s_scaler.fit_transform(X_train.astype(np.float))\n",
    "X_test = s_scaler.transform(X_test.astype(np.float))\n",
    "\n",
    "eg(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maching learning models\n",
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "# train first\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# ... then predict--on both the training AND the test set\n",
    "y_train_prediction = lr.predict(X_train)\n",
    "y_test_prediction = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example plot\n",
    "It is hard to plot this model because it is high dimension. However, for example purposes, I'll plot the age variable (column 0 from the design matrix) vs. the 'charges' variable which we are trying to predict. In other words, we're now looking at a 1 dimensional abstraction from the entire model. \n",
    "\n",
    "Note that the age variable (on the x-axis) has been standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training data\n",
    "plt.plot(X_train[:,0], y_train, '.', label=\"Training data\")\n",
    "\n",
    "# training features. Note that it doesn't matter whether we use\n",
    "# training or test data here; as they would both just be input \n",
    "# as the independent variables into the linear model below.\n",
    "_x = X_train[:,0].copy()\n",
    "\n",
    "# basic 1 dimensional linear model (i.e. y = mx + c) \n",
    "_prediction = _x * lr.coef_.ravel()[0] + lr.intercept_\n",
    "\n",
    "plt.plot(X_train[:,0], _prediction, label=\"Model prediction\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylabel(\"charges\")\n",
    "plt.xlabel(\"age (standardized)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back into the full dimensional system..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient: [[3624.36356197 1966.90473927  661.35603447  242.57758422  -29.49212715\n",
      "  -104.19142495  -99.14488063  -44.54996175 9310.54961689]]\n",
      "Intercept: [13141.35083164]\n",
      "Training set score: 0.728; Test set score: 0.786\n"
     ]
    }
   ],
   "source": [
    "# print out the gradient and intercept of the line\n",
    "\n",
    "print(f\"Gradient: {lr.coef_}\")\n",
    "print(f\"Intercept: {lr.intercept_}\")\n",
    "\n",
    "print(\n",
    "    \"Training set score: %.3f; Test set score: %.3f\" % (\n",
    "        lr.score(X_train, y_train),\n",
    "        lr.score(X_test, y_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POLYNOMIAL REGESSION\n",
    "Note that polynomial regression is still a subset of linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice the huge change in number of columns:\n",
      "\n",
      "X_train_poly shape: \t(896, 220)\n",
      "X_test_poly shape: \t(442, 220)\n",
      "\n",
      "X_train shape: \t(896, 9)\n",
      "X_test shape: \t(442, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_poly = poly.fit_transform(X_final)\n",
    "\n",
    "# could you put this line before making the X_poly matrix?\n",
    "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X_poly, y_final, test_size=0.33, random_state=0)\n",
    "print(\"Notice the huge change in number of columns:\\n\")\n",
    "print(\"X_train_poly shape: \\t%s\" % str(X_train_poly.shape))\n",
    "print(\"X_test_poly shape: \\t%s\" % str(X_test_poly.shape))\n",
    "print()\n",
    "print(\"X_train shape: \\t%s\" % str(X_train.shape))\n",
    "print(\"X_test shape: \\t%s\" % str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing\n",
    "\n",
    "#standard scaler (fit transform on train, fit only on test)\n",
    "sc = StandardScaler()\n",
    "X_train_final_poly = sc.fit_transform(X_train_poly.astype(np.float))\n",
    "X_test_final_poly = sc.transform(X_test_poly.astype(np.float))\n",
    "\n",
    "# (why do we not apply normalization?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_lr = LinearRegression()\n",
    "poly_lr.fit(X_train_final_poly, y_train_poly)\n",
    "\n",
    "# use these to make plots ...\n",
    "y_train_pred = poly_lr.predict(X_train_final_poly)\n",
    "y_test_pred = poly_lr.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.38221886e-13 -2.00328934e+15  1.94967630e+15 -1.88619598e+15\n",
      "   7.07981961e+15  3.12607250e+15  2.90905638e+15  1.83393980e+15\n",
      "   3.89287551e+14 -4.66675630e+14  3.65619477e+14  1.05561285e+15\n",
      "   1.95500892e+14  1.75236367e+15  1.58085400e+15  5.68046159e+14\n",
      "   1.52617237e+15 -3.56727204e+14  2.38854263e+14 -5.64426982e+14\n",
      "  -8.40929241e+14 -2.00239750e+15 -1.95580622e+15 -2.29953448e+15\n",
      "  -2.39355706e+15  8.35623848e+13  1.26311680e+15  8.22272302e+13\n",
      "   3.11846624e+14  6.95081692e+14  5.85271490e+14  3.97941758e+14\n",
      "  -3.16334526e+14  3.92408934e+13 -7.69676750e+14  6.39476356e+13\n",
      "   1.41129610e+14 -1.78262473e+13  2.97137013e+14  6.61499215e+14\n",
      "   1.17501592e+15  1.09298561e+13  2.68296687e+13  6.82024709e+13\n",
      "   1.60635641e+14  1.44030776e+15  2.54221835e+13  3.15431509e+14\n",
      "  -6.83204359e+13  1.96335805e+15  1.40117735e+14  9.16214707e+13\n",
      "  -4.28731122e+14  5.84465169e+13 -3.24881093e+14 -1.89500000e+03\n",
      "   2.93025000e+03  4.61275000e+03 -3.02943233e+14 -3.10050034e+14\n",
      "  -3.14776629e+14 -3.03331101e+14 -2.77750000e+02 -3.19600000e+03\n",
      "   2.27443750e+03 -1.10875000e+02 -1.12363380e+15 -1.12535625e+15\n",
      "  -1.30819769e+15 -1.19294571e+15 -5.65431250e+03  3.95475000e+03\n",
      "   1.66181250e+03 -1.12186791e+14 -1.20185818e+14 -1.23560397e+14\n",
      "  -1.28816111e+14 -7.37500000e+00 -5.01375000e+02  8.39386979e+14\n",
      "   2.58499255e+12 -2.11653733e+12 -1.11321393e+12  5.35240821e+14\n",
      "   7.16272709e+13  1.06953879e+15 -1.30430737e+12  1.20572175e+12\n",
      "   5.52824002e+14  7.35855063e+13  2.13556771e+15 -2.96303412e+11\n",
      "   5.88758017e+14  9.05736315e+13  1.10457163e+15  5.42813998e+14\n",
      "   5.55851779e+13 -5.26516531e+14  1.12662500e+03 -3.76217910e+14\n",
      "  -1.46705000e+04 -8.12550000e+03  5.92350113e+14  5.78165892e+14\n",
      "   8.12580931e+14  6.59833938e+14 -5.14500000e+03  3.37500000e+02\n",
      "  -2.38200000e+03  4.71208523e+14  4.92713813e+14  5.64808190e+14\n",
      "   5.77477450e+14  1.48950000e+03 -3.81320312e+03 -1.99883985e+15\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -5.78495742e+13\n",
      "  -1.61583999e+14 -2.06783323e+15  0.00000000e+00  0.00000000e+00\n",
      "  -5.71162636e+13 -1.51623299e+14 -2.53477486e+15  0.00000000e+00\n",
      "  -7.32623094e+13 -2.19855184e+14 -1.92645352e+15 -6.34520958e+13\n",
      "  -1.56095412e+14  1.43253606e+13 -1.62412500e+03 -9.40900030e+14\n",
      "   1.12256250e+03 -4.35158725e+13 -4.07249156e+13 -4.34654669e+13\n",
      "  -5.67018796e+13 -1.45437500e+02  8.36250000e+02  8.33243314e+14\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -7.15951319e+13\n",
      "   7.12913806e+12  4.52891750e+14  0.00000000e+00  0.00000000e+00\n",
      "  -6.45795995e+13  7.08424407e+12  5.93143158e+14  0.00000000e+00\n",
      "  -6.88911618e+13  7.95434892e+12  9.22890727e+14 -7.66735071e+13\n",
      "   7.02413831e+12  4.44259279e+14 -1.17312500e+02 -5.33011180e+13\n",
      "  -7.80394302e+14  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   5.26911978e+14  2.93799268e+13  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.31571030e+14  1.29638817e+14\n",
      "   2.93799268e+13  1.31057910e+15  0.00000000e+00  0.00000000e+00\n",
      "   1.11531672e+14 -2.78407718e+14  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.11531672e+14  1.05367738e+14  7.97860392e+14\n",
      "   1.48334511e+15  0.00000000e+00 -3.98971276e+14  4.53939266e+14\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  3.97539839e+14\n",
      "   1.55641068e+14  4.53939266e+14  1.93345440e+15  7.85623710e+13\n",
      "   3.84212783e+14  7.85623710e+13  1.14092162e+14  1.69936240e+14\n",
      "  -4.15177244e+14 -7.33131541e+13 -2.29382485e+14 -5.41131907e+14]]\n",
      "\n",
      "[13131.04634292]\n"
     ]
    }
   ],
   "source": [
    "print(poly_lr.coef_)\n",
    "print()\n",
    "print(poly_lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For comparisson:\n",
      "\n",
      "Simple linear train score: \t0.728; \tSimple linear test score: \t0.786\n",
      "Poly train score: \t\t0.841; \tPoly test score: \t\t0.854\n"
     ]
    }
   ],
   "source": [
    "print(\"For comparisson:\\n\\nSimple linear train score: \\t%.3f; \\tSimple linear test score: \\t%.3f\" % (\n",
    "    lr.score(X_train, y_train),\n",
    "    lr.score(X_test, y_test)\n",
    "))\n",
    "print(\"Poly train score: \\t\\t%.3f; \\tPoly test score: \\t\\t%.3f\" % (\n",
    "    poly_lr.score(X_train_final_poly, y_train_poly),\n",
    "    poly_lr.score(X_test_final_poly, y_test_poly)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SVR, X_test_SVR, y_train_SVR, y_test_SVR = train_test_split(X_final, y_final, test_size=0.33,\n",
    "                                                                    random_state=0)\n",
    "\n",
    "# SVR can be affected by outliers, so it's extra important to apply scaling. \n",
    "# Remember that the reason we want to scale is because we want to avoid features\n",
    "# with larger values to dominate the model result.\n",
    "sc = StandardScaler()\n",
    "X_train_SVR = sc.fit_transform(X_train_SVR.astype(np.float))\n",
    "X_test_SVR = sc.fit_transform(X_test_SVR.astype(np.float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=300, kernel='linear')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR(kernel=\"linear\", C=300)\n",
    "svr.fit(X_train_SVR, y_train_SVR.values[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = svr.predict(X_train_SVR)\n",
    "y_test_pred = svr.predict(X_test_SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For comparisson:\n",
      "\n",
      "Simple linear train score: \t0.728; \tSimple linear test score: \t0.786\n",
      "Poly train score: \t\t0.841; \tPoly test score: \t\t0.854\n",
      "SVR train score: \t\t0.598; \tSVR test score: \t\t0.619\n",
      "\n",
      "Note: the SVR test score comes out slightly differently to the instructor's example...\n",
      "Theirs comes out as 0.628.\n"
     ]
    }
   ],
   "source": [
    "print(\"For comparisson:\\n\\nSimple linear train score: \\t%.3f; \\tSimple linear test score: \\t%.3f\" % (\n",
    "    lr.score(X_train, y_train),\n",
    "    lr.score(X_test, y_test)\n",
    "))\n",
    "print(\"Poly train score: \\t\\t%.3f; \\tPoly test score: \\t\\t%.3f\" % (\n",
    "    poly_lr.score(X_train_final_poly, y_train_poly),\n",
    "    poly_lr.score(X_test_final_poly, y_test_poly)\n",
    "))\n",
    "print(\"SVR train score: \\t\\t%.3f; \\tSVR test score: \\t\\t%.3f\" % (\n",
    "    svr.score(X_train_SVR, y_train_SVR),\n",
    "    svr.score(X_test_SVR, y_test_SVR)\n",
    "))\n",
    "print(\"\\nNote: the SVR test score comes out slightly differently to the instructor's example...\"\n",
    "      \"\\nTheirs comes out as 0.628.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION TREE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For comparisson:\n",
      "\n",
      "Simple linear train score: \t0.728; \tSimple linear test score: \t0.786\n",
      "Poly train score: \t\t0.841; \tPoly test score: \t\t0.854\n",
      "SVR train score: \t\t0.598; \tSVR test score: \t\t0.619\n",
      "DTR train score: \t\t1.000; \tDTR test score: \t\t0.697\n",
      "\n",
      "Notice the test score is worse than the training score. This shows the model is overfit.\n",
      "This is the tendency for tree regressors.\n"
     ]
    }
   ],
   "source": [
    "X_train_dt, X_test_dt, y_train_dt, y_test_dt = split_and_scale(X_final, y_final, random_state=0)\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=0)\n",
    "dt.fit(X_train_dt, y_train_dt.values[:,0])\n",
    "\n",
    "y_train_pred = dt.predict(X_train_dt)\n",
    "y_test_pred = dt.predict(X_test_dt)\n",
    "\n",
    "print(\"For comparisson:\\n\\nSimple linear train score: \\t%.3f; \\tSimple linear test score: \\t%.3f\" % (\n",
    "    lr.score(X_train, y_train),\n",
    "    lr.score(X_test, y_test)\n",
    "))\n",
    "print(\"Poly train score: \\t\\t%.3f; \\tPoly test score: \\t\\t%.3f\" % (\n",
    "    poly_lr.score(X_train_final_poly, y_train_poly),\n",
    "    poly_lr.score(X_test_final_poly, y_test_poly)\n",
    "))\n",
    "print(\"SVR train score: \\t\\t%.3f; \\tSVR test score: \\t\\t%.3f\" % (\n",
    "    svr.score(X_train_SVR, y_train_SVR),\n",
    "    svr.score(X_test_SVR, y_test_SVR)\n",
    "))\n",
    "print(\"DTR train score: \\t\\t%.3f; \\tDTR test score: \\t\\t%.3f\" % (\n",
    "    dt.score(X_train_dt, y_train_dt),\n",
    "    dt.score(X_test_dt, y_test_dt)\n",
    "))\n",
    "print(\n",
    "    \"\\nNotice the test score is worse than the training score. This shows the model is overfit.\"\n",
    "    \"\\nThis is the tendency for tree regressors.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For comparisson:\n",
      "\n",
      "Simple linear train score: \t0.728; \tSimple linear test score: \t0.786\n",
      "Poly train score: \t\t0.841; \tPoly test score: \t\t0.854\n",
      "SVR train score: \t\t0.598; \tSVR test score: \t\t0.619\n",
      "DTR train score: \t\t1.000; \tDTR test score: \t\t0.697\n",
      "RF train score: \t\t0.979; \tRF test score: \t\t\t0.816\n",
      "Notice that in this 'ensemble learning method' (that is, the random forest),\n",
      "the test score is much better when compared to a single tree.\n"
     ]
    }
   ],
   "source": [
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = split_and_scale(X_final, y_final, random_state=0)\n",
    "\n",
    "forest = RandomForestRegressor(n_estimators = 100,\n",
    "                              criterion = 'mse',\n",
    "                              random_state = 1,\n",
    "                              n_jobs = -1)\n",
    "forest.fit(X_train_rf, y_train_rf.values[:,0])\n",
    "y_train_pred = forest.predict(X_train_rf)\n",
    "y_test_pred = forest.predict(X_test_rf)\n",
    "\n",
    "print(\"For comparisson:\\n\\nSimple linear train score: \\t%.3f; \\tSimple linear test score: \\t%.3f\" % (\n",
    "    lr.score(X_train, y_train),\n",
    "    lr.score(X_test, y_test)\n",
    "))\n",
    "print(\"Poly train score: \\t\\t%.3f; \\tPoly test score: \\t\\t%.3f\" % (\n",
    "    poly_lr.score(X_train_final_poly, y_train_poly),\n",
    "    poly_lr.score(X_test_final_poly, y_test_poly)\n",
    "))\n",
    "print(\"SVR train score: \\t\\t%.3f; \\tSVR test score: \\t\\t%.3f\" % (\n",
    "    svr.score(X_train_SVR, y_train_SVR),\n",
    "    svr.score(X_test_SVR, y_test_SVR)\n",
    "))\n",
    "print(\"DTR train score: \\t\\t%.3f; \\tDTR test score: \\t\\t%.3f\" % (\n",
    "    dt.score(X_train_dt, y_train_dt),\n",
    "    dt.score(X_test_dt, y_test_dt)\n",
    "))\n",
    "print(\"RF train score: \\t\\t%.3f; \\tRF test score: \\t\\t\\t%.3f\" % (\n",
    "    forest.score(X_train_rf, y_train_rf),\n",
    "    forest.score(X_test_rf, y_test_rf)\n",
    "))\n",
    "print(\n",
    "    \"Notice that in this 'ensemble learning method' (that is, the random forest),\\n\"\n",
    "    \"the test score is much better when compared to a single tree.\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END .C=600, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END .C=600, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END .C=600, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END .C=600, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END .C=600, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ...C=600, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 2/5] END ...C=600, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 3/5] END ...C=600, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 4/5] END ...C=600, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 5/5] END ...C=600, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 1/5] END ..C=600, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END ..C=600, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END ..C=600, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END ..C=600, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END ..C=600, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ....C=600, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 2/5] END ....C=600, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 3/5] END ....C=600, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 4/5] END ....C=600, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 5/5] END ....C=600, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 1/5] END ..C=600, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END ..C=600, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END ..C=600, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END ..C=600, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END ..C=600, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ....C=600, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 2/5] END ....C=600, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 3/5] END ....C=600, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 4/5] END ....C=600, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 5/5] END ....C=600, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 1/5] END .C=700, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END .C=700, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END .C=700, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END .C=700, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END .C=700, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ...C=700, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 2/5] END ...C=700, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 3/5] END ...C=700, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 4/5] END ...C=700, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 5/5] END ...C=700, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 1/5] END ..C=700, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END ..C=700, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END ..C=700, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END ..C=700, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END ..C=700, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ....C=700, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 2/5] END ....C=700, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 3/5] END ....C=700, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 4/5] END ....C=700, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 5/5] END ....C=700, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 1/5] END ..C=700, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END ..C=700, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END ..C=700, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END ..C=700, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END ..C=700, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ....C=700, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 2/5] END ....C=700, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 3/5] END ....C=700, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 4/5] END ....C=700, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 5/5] END ....C=700, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 1/5] END .C=800, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END .C=800, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END .C=800, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END .C=800, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END .C=800, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ...C=800, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 2/5] END ...C=800, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 3/5] END ...C=800, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 4/5] END ...C=800, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 5/5] END ...C=800, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 1/5] END ..C=800, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END ..C=800, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END ..C=800, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END ..C=800, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END ..C=800, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ....C=800, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 2/5] END ....C=800, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 3/5] END ....C=800, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 4/5] END ....C=800, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 5/5] END ....C=800, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 1/5] END ..C=800, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END ..C=800, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END ..C=800, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END ..C=800, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END ..C=800, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ....C=800, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 2/5] END ....C=800, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 3/5] END ....C=800, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 4/5] END ....C=800, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 5/5] END ....C=800, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 1/5] END .C=900, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END .C=900, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END .C=900, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END .C=900, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END .C=900, degree=2, epsilon=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ...C=900, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 2/5] END ...C=900, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 3/5] END ...C=900, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 4/5] END ...C=900, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 5/5] END ...C=900, degree=2, epsilon=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV 1/5] END ..C=900, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END ..C=900, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END ..C=900, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END ..C=900, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END ..C=900, degree=2, epsilon=1e-05, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ....C=900, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=900, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 3/5] END ....C=900, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 4/5] END ....C=900, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 5/5] END ....C=900, degree=2, epsilon=1e-05, kernel=poly; total time=   0.0s\n",
      "[CV 1/5] END ..C=900, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 2/5] END ..C=900, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 3/5] END ..C=900, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 4/5] END ..C=900, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 5/5] END ..C=900, degree=2, epsilon=1e-06, kernel=linear; total time=   0.0s\n",
      "[CV 1/5] END ....C=900, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 2/5] END ....C=900, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 3/5] END ....C=900, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 4/5] END ....C=900, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n",
      "[CV 5/5] END ....C=900, degree=2, epsilon=1e-06, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid={'C': [600, 700, 800, 900], 'degree': [2],\n",
       "                         'epsilon': [0.0001, 1e-05, 1e-06],\n",
       "                         'kernel': ['linear', 'poly']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HYPERPARAMETER OPTIMIZATION for support vector regressioin\n",
    "\n",
    "#Function to print best hyperparamaters: \n",
    "def print_best_params(gd_model):\n",
    "    param_dict = gd_model.best_estimator_.get_params()\n",
    "    model_str = str(gd_model.estimator).split('(')[0]\n",
    "    print(\"\\n*** {} Best Parameters ***\".format(model_str))\n",
    "    for k in param_dict:\n",
    "        print(\"{}: {}\".format(k, param_dict[k]))\n",
    "    print()\n",
    "\n",
    "X_train_, X_test_, y_train_, y_test_ = split_and_scale(X_final, y_final, random_state=0)\n",
    "\n",
    "# parameters that the model can take on.\n",
    "# C: penalty parameter on the error term.\n",
    "# epsilon: margin of tolerance where no penalty is given to errors\n",
    "param_grid = dict(\n",
    "    kernel=     ['linear', 'poly'],\n",
    "    degree=     [2],\n",
    "    C=          [600, 700, 800, 900],\n",
    "    epsilon=    [0.0001, 0.00001, 0.000001]\n",
    ")\n",
    "\n",
    "# return a GridSearchCV object.\n",
    "# cv: cross validation\n",
    "svr_gridsearch = GridSearchCV(SVR(), param_grid=param_grid, cv=5, verbose=3)\n",
    "\n",
    "svr_gridsearch.fit(X_train_, y_train_.values[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** SVR Best Parameters ***\n",
      "C: 800\n",
      "cache_size: 200\n",
      "coef0: 0.0\n",
      "degree: 2\n",
      "epsilon: 1e-05\n",
      "gamma: scale\n",
      "kernel: linear\n",
      "max_iter: -1\n",
      "shrinking: True\n",
      "tol: 0.001\n",
      "verbose: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_best_params(svr_gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For comparisson:\n",
      "\n",
      "Simple linear train score: \t0.728; \tSimple linear test score: \t0.786\n",
      "Poly train score: \t\t0.841; \tPoly test score: \t\t0.854\n",
      "SVR train score: \t\t0.598; \tSVR test score: \t\t0.619\n",
      "DTR train score: \t\t1.000; \tDTR test score: \t\t0.697\n",
      "RF train score: \t\t0.979; \tRF test score: \t\t\t0.816\n",
      "SVR train score (grid search): \t0.687; \tSVR test score (grid search): \t0.632\n"
     ]
    }
   ],
   "source": [
    "print(\"For comparisson:\\n\\nSimple linear train score: \\t%.3f; \\tSimple linear test score: \\t%.3f\" % (\n",
    "    lr.score(X_train, y_train),\n",
    "    lr.score(X_test, y_test)\n",
    "))\n",
    "print(\"Poly train score: \\t\\t%.3f; \\tPoly test score: \\t\\t%.3f\" % (\n",
    "    poly_lr.score(X_train_final_poly, y_train_poly),\n",
    "    poly_lr.score(X_test_final_poly, y_test_poly)\n",
    "))\n",
    "print(\"SVR train score: \\t\\t%.3f; \\tSVR test score: \\t\\t%.3f\" % (\n",
    "    svr.score(X_train_SVR, y_train_SVR),\n",
    "    svr.score(X_test_SVR, y_test_SVR)\n",
    "))\n",
    "print(\"DTR train score: \\t\\t%.3f; \\tDTR test score: \\t\\t%.3f\" % (\n",
    "    dt.score(X_train_dt, y_train_dt),\n",
    "    dt.score(X_test_dt, y_test_dt)\n",
    "))\n",
    "print(\"RF train score: \\t\\t%.3f; \\tRF test score: \\t\\t\\t%.3f\" % (\n",
    "    forest.score(X_train_rf, y_train_rf),\n",
    "    forest.score(X_test_rf, y_test_rf)\n",
    "))\n",
    "print(\"SVR train score (grid search): \\t%.3f; \\tSVR test score (grid search): \\t%.3f\" % (\n",
    "    svr_gridsearch.score(X_train_, y_train_),\n",
    "    svr_gridsearch.score(X_test_, y_test_)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYPER PARAMETER OPTIMZATION: TREE MODEL AND RANDOM FOREST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(random_state=0),\n",
       "             param_grid={'criterion': ['mse', 'friedman_mse', 'mae', 'poisson'],\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6, None],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2']})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train__, X_test__, y_train__, y_test__ = split_and_scale(X_final, y_final, random_state=0)\n",
    "\n",
    "# decision tree model\n",
    "param_grid = dict(\n",
    "    max_depth =     [1,2,3,4,5,6,None],\n",
    "    max_features =  ['auto', 'sqrt', 'log2'],\n",
    "    criterion =     [\"mse\",\"friedman_mse\", \"mae\", \"poisson\"]\n",
    ")\n",
    "\n",
    "tree_gridsearch = GridSearchCV(\n",
    "    DecisionTreeRegressor(random_state=0), \n",
    "    param_grid=param_grid, \n",
    "    cv=5)\n",
    "\n",
    "tree_gridsearch.fit(X_train__, y_train__.values[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For comparisson:\n",
      "\n",
      "Simple linear train score: \t0.728; \tSimple linear test score: \t0.786\n",
      "Poly train score: \t\t0.841; \tPoly test score: \t\t0.854\n",
      "SVR train score: \t\t0.598; \tSVR test score: \t\t0.619\n",
      "DTR train score: \t\t1.000; \tDTR test score: \t\t0.697\n",
      "RF train score: \t\t0.979; \tRF test score: \t\t\t0.816\n",
      "SVR train score (grid search): \t0.687; \tSVR test score (grid search): \t0.632\n",
      "DTR train score (grid search): \t0.857; \tDTR test score (grid search): \t0.839\n"
     ]
    }
   ],
   "source": [
    "print(\"For comparisson:\\n\\nSimple linear train score: \\t%.3f; \\tSimple linear test score: \\t%.3f\" % (\n",
    "    lr.score(X_train, y_train),\n",
    "    lr.score(X_test, y_test)\n",
    "))\n",
    "print(\"Poly train score: \\t\\t%.3f; \\tPoly test score: \\t\\t%.3f\" % (\n",
    "    poly_lr.score(X_train_final_poly, y_train_poly),\n",
    "    poly_lr.score(X_test_final_poly, y_test_poly)\n",
    "))\n",
    "print(\"SVR train score: \\t\\t%.3f; \\tSVR test score: \\t\\t%.3f\" % (\n",
    "    svr.score(X_train_SVR, y_train_SVR),\n",
    "    svr.score(X_test_SVR, y_test_SVR)\n",
    "))\n",
    "print(\"DTR train score: \\t\\t%.3f; \\tDTR test score: \\t\\t%.3f\" % (\n",
    "    dt.score(X_train_dt, y_train_dt),\n",
    "    dt.score(X_test_dt, y_test_dt)\n",
    "))\n",
    "print(\"RF train score: \\t\\t%.3f; \\tRF test score: \\t\\t\\t%.3f\" % (\n",
    "    forest.score(X_train_rf, y_train_rf),\n",
    "    forest.score(X_test_rf, y_test_rf)\n",
    "))\n",
    "print(\"SVR train score (grid search): \\t%.3f; \\tSVR test score (grid search): \\t%.3f\" % (\n",
    "    svr_gridsearch.score(X_train_, y_train_),\n",
    "    svr_gridsearch.score(X_test_, y_test_)\n",
    "))\n",
    "print(\"DTR train score (grid search): \\t%.3f; \\tDTR test score (grid search): \\t%.3f\" % (\n",
    "    tree_gridsearch.score(X_train__, y_train__),\n",
    "    tree_gridsearch.score(X_test__, y_test__)\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
